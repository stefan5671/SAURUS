function [output_signals, synthesis_struct] = compass_synthesis(compass_signals, synthesis_struct, compass_parameters)
% COMPASS_SNYTHESIS The COMPASS method performing the sythesis based on the spatial analysis
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% This file is part of the COMPASS reference implementation, as described
% in the publication
%
%   Archontis Politis, Sakari Tervo, and Ville Pulkki. 2018. 
%   "COMPASS: Coding and multidirectional parameterization of ambisonic 
%   sound scenes." 
%   IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP).
%
% Author:   Archontis Politis (archontis.politis@gmail.com)
% Copyright (C) 2021 - Archontis Politis & Leo McCormack
% 
% The COMPASS reference code is free software; you can redistribute it 
% and/or modify it under the terms of the GNU General Public License as 
% published by the Free Software Foundation; either version 2 of the 
% License, or (at your option) any later version.
% 
% The COMPASS reference code is distributed in the hope that it will be 
% useful, but WITHOUT ANY WARRANTY; without even the implied warranty of 
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General 
% Public License for more details.
% 
% You should have received a copy of the GNU General Public License along 
% with this program; if not, see <https://www.gnu.org/licenses/>.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% INPUT ARGUMENTS
%
% compass_signals       % time-frequency transformed signals as produced by
%                         COMPASS_ANALYSIS.m
% synthesis_struct      % structure with time-frequency transform, spatial 
%                         modification and rendering parameters
%                         generated by COMPASS_SYNTHESIS_INIT.m
% compass_parameters    % analyzed spatial parameters as generated by
%                         COMPASS_ANALYSIS.m
%
% OUTPUT ARGUMENTS
%
% output_signals        % [lSig x nCHout] loudspeaker or headphone 
%                         time-domain output signals
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Initializations
hopsize = synthesis_struct.hopSize;
blocksize = synthesis_struct.blockSize;
nFrames = synthesis_struct.nFramesInBlock;
nBands = length(synthesis_struct.bandFreq);

nSH = size(compass_signals,1);
order = sqrt(nSH)-1;
nBlocks = size(compass_signals,4);

eq = synthesis_struct.eq;
strBal = synthesis_struct.streamBalance;
decBal = synthesis_struct.decodeBalance;
diffBal = synthesis_struct.diffusionLevel;
nDiff = size(synthesis_struct.SHgrid_diff,1);
Ad = synthesis_struct.SHgrid_diff;
M_dec_diff = Ad/nDiff;
nCHout = size(synthesis_struct.vbap_gtable,1);
M_dec = repmat(synthesis_struct.ambiDec, [1 1 nBands]);
nElimDoas = 0; 

% afSTFT initialization/allocation
afSTFTdelay = 12*hopsize;
afSTFT(hopsize, nSH, nCHout, 'hybrid');
output_signals_ls = zeros(afSTFTdelay+hopsize*(nBlocks+1), nCHout);
 
new_Ms = zeros(nCHout,nSH,nBands);
new_Md = zeros(nDiff,nSH,nBands);
current_Ms = M_dec/2;
current_Md = repmat(M_dec_diff/2, [1 1 nBands])/2;

% Allocate decorrelation and transient extraction buffers
nBlocksInBuffer         = ceil((32+nFrames)/nFrames);
nbib_1                  = nBlocksInBuffer-1;
ambientBlock            = zeros(nDiff,nFrames,nBands);
ambientBufferXBlocks    = zeros(nDiff,nBlocksInBuffer*nFrames,nBands);
decAmbientBlock = zeros(nDiff,nFrames);
ducker_struct.transientDetector1 = zeros(nDiff, 1, nBands);
ducker_struct.transientDetector2 = zeros(nDiff, 1, nBands);

% gain factors for source + ambient streams
gs = 2 * 1;
gd = 2 * sqrt(1/nSH);

% Process loop
startIndex = 1;
blockIndex = 1;
progress = 1;
prevInputBlock = zeros(nSH, nFrames, nBands);
while blockIndex <= nBlocks
    % display progress
    if blockIndex*10/nBlocks > progress
        fprintf('*');
        progress=progress+1;
    end

    % fetch next block multichannel spectrogram
    newInputBlock = compass_signals(:,:,:,blockIndex); % [nCH x nFramesInBlock x nBins]

    % Loop over ERB band groupings
    for erband=1:synthesis_struct.nERBands-1
        % fetch the estimated parameters for this ERB band
        erb_bins = synthesis_struct.ERBbinIdx(erband):synthesis_struct.ERBbinIdx(erband+1)-1;  
        nSrc = compass_parameters.nSrc(erb_bins(1), blockIndex);
        doa_idx = compass_parameters.doa_idx(1:nSrc, erb_bins(1), blockIndex);
        
        % for multiple DoAs, merge those that are closely spaced 
        if doa_idx>1
            [new_doa_xyz, nelimd] = eliminateAdjacentDOAs(synthesis_struct.DOAgrid(doa_idx,:), synthesis_struct.nullAngSepThresh(order));
        else
            new_doa_xyz = synthesis_struct.DOAgrid(doa_idx,:);
            nelimd = 0;
        end
        if nelimd
            doa_idx = findClosestGridPoints(synthesis_struct.DOAgrid, new_doa_xyz);
            nElimDoas = nElimDoas+nelimd;
        end

        % COMPASS matrices
        As = synthesis_struct.SHgrid(doa_idx,:).';  % source beamformers
        Ds = pinv(As);                              % steer nulls to other sources
        Dd = eye(nSH) - As*Ds;                      % residual (after sources are subtracted from input field)

        % Formulate mixing matrices per band
        gains_nerb = synthesis_struct.vbap_gtable(:,doa_idx); % VBAP gains
        for band = erb_bins
            if synthesis_struct.vbap_pValue(band) ~= 2
                % apply frequency-dependent VBAP normalization, if needed
                pVal_nb = synthesis_struct.vbap_pValue(band);
                gains_nb = gains_nerb./(ones(nLS,1) * sum(gains_nerb.^pVal_nb).^(1/pVal_nb));
            else
                gains_nb = gains_nerb;
            end
            
            % mixing gains between source (a) and ambient (b) stream
            if strBal(band)<1
                a = strBal(band); 
                b = 1;
            elseif (strBal(band)>=1) && (strBal(band)<=2)
                a = 1; 
                b = 2-strBal(band);
            end
            
            % Source and ambient stream rendering matrices
            new_Ms(:,:,band) = eq(band)*a*(gs*decBal(band)*gains_nb*Ds + (1-decBal(band))*M_dec(:,:,band)/2);
            new_Md(:,:,band) = eq(band)*b*M_dec_diff*(gd*decBal(band)*Dd + (1-decBal(band))*eye(nSH)/2);
            
        end
    end 
    
    % Apply rendering matrices
    interpolator = (1:nFrames)'/nFrames;
    outputBlock = zeros(nCHout,nFrames,nBands);
    for band=1:nBands
        for frame=1:nFrames
            % source frames
            interp_Ms = interpolator(frame)*new_Ms(:,:,band) + (1-interpolator(frame))*current_Ms(:,:,band);
            outputBlock(:,frame,band) = interp_Ms * prevInputBlock(:,frame,band);
            % ambient frames
            interp_Md = interpolator(frame)*new_Md(:,:,band) + (1-interpolator(frame))*current_Md(:,:,band);
            ambientBlock(:,frame,band) = interp_Md * prevInputBlock(:,frame,band);
        end
    end
    
    % extract transients from ambient stream and add to decorrelation buffer
    ambientBufferXBlocks(:,1:nbib_1*nFrames,:) = ambientBufferXBlocks(:,nFrames+1:end,:);
    alpha = 0.95;
    beta = 0.995; 
    [ambientBufferXBlocks(:,nbib_1*nFrames+1:end,:), ducker_struct] = extractTransients(ambientBlock, alpha, beta, ducker_struct);  
 
    % Handle ambient stream
    for band=1:nBands
        % rendering gains for ambient plane waves (12 ~ 60)
        gains_diff_nb = synthesis_struct.vbap_gtable_diff;
        if synthesis_struct.vbap_pValue(band) ~= 2
            % apply frequency-dependent VBAP normalization, if needed
            pVal_nb = synthesis_struct.vbap_pValue(band);
            gains_diff_nb = synthesis_struct.vbap_gtable_diff;
            gains_diff_nb = gains_diff_nb./(ones(nCHout,1) * sum(gains_diff_nb.^pVal_nb).^(1/pVal_nb));
        end

        % get decorrelated frames from decorrelation buffer
        for ch=1:nDiff
            decDelay = synthesis_struct.decorrelationDelays(ch,band);
            decAmbientBlock(ch,:) = ambientBufferXBlocks(ch,(nbib_1*nFrames+1:end)-decDelay,band);
        end 
        % render ambient block at defined diffusion level 
        outputAmbientBlock = gains_diff_nb*((1-diffBal)*ambientBlock(:,:,band) + decBal(band)*diffBal*decAmbientBlock);
        
        % mix source and ambient streams
        outputBlock(:,:,band) = outputBlock(:,:,band) + outputAmbientBlock;
    end
 
    % permute back to (nBands,nFrames,nChan)
    tempOut = permute(outputBlock, [3 2 1]);
    % time-domain range of current block
    TDrange = startIndex + (0:blocksize-1);
    % write to output signal
    output_signals_ls(TDrange,:)= afSTFT(tempOut);
    
    prevInputBlock = newInputBlock;
    startIndex = startIndex + blocksize;
    blockIndex = blockIndex+1;
    
    current_Ms = new_Ms;
    new_Ms(:) = 0;
    current_Md = new_Md;
    new_Md(:) = 0;
end
fprintf('\n')

output_signals_ls = output_signals_ls(afSTFTdelay+(1:((nBlocks-1)*blocksize)),:);  
synthesis_struct.nElimDoas = nElimDoas;

% STFT destroy
afSTFT();

% convolve with nearest HRTFs for headphone monitoring if enabled
if synthesis_struct.mode
    output_signals(:,1) = sum(fftfilt(squeeze(synthesis_struct.hrirs(:,1,:)), output_signals_ls),2);
    output_signals(:,2) = sum(fftfilt(squeeze(synthesis_struct.hrirs(:,2,:)), output_signals_ls),2);
else
    output_signals = output_signals_ls;
end

end
